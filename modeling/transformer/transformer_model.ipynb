{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "WCV-KJEVgxYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EC2UqeUQftho"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2bAzFd8f-cq",
        "outputId": "f8f0554c-e345-45ae-c44b-02d9c14c53a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_PATH = \"gdrive/MyDrive/ChamoAnalytics\""
      ],
      "metadata": {
        "id": "MBoat1NmgA9n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f\"{DIR_PATH}/master_dataset.csv\", na_values=['-1'])"
      ],
      "metadata": {
        "id": "kAg5iqWsgB1_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "KEU22vVxvAF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace('.', np.nan)\n",
        "df[[\" us_bank_rate\"]] = df[[\" us_bank_rate\"]].apply(pd.to_numeric)\n",
        "df = df.rename(columns={' us_bank_rate': 'us_bank_rate'})"
      ],
      "metadata": {
        "id": "rgDu6Brieh2l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFIyISyXb371",
        "outputId": "999a2244-c561-40ca-b495-3c731dcc280a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date                            object\n",
              "rate                           float64\n",
              "sent_fin_us_uncertainty        float64\n",
              "sent_fin_us_litigious          float64\n",
              "sent_fin_us_strong_modal       float64\n",
              "sent_fin_us_weak_modal         float64\n",
              "sent_fin_us_constraining       float64\n",
              "sent_fin_us_optimistic         float64\n",
              "sent_fin_can_uncertainty       float64\n",
              "sent_fin_can_litigious         float64\n",
              "sent_fin_can_strong_modal      float64\n",
              "sent_fin_can_weak_modal        float64\n",
              "sent_fin_can_constraining      float64\n",
              "sent_fin_can_optimistic        float64\n",
              "ti_rate_rsi_14                 float64\n",
              "ti_rate_stochrsi_14            float64\n",
              "ti_rate_macd_12_26             float64\n",
              "ti_rate_adx_14                 float64\n",
              "ti_rate_williams_%R            float64\n",
              "ti_rate_cci                    float64\n",
              "ti_rate_atr                    float64\n",
              "ti_rate_utlimate_oscillator    float64\n",
              "ti_rate_roc                    float64\n",
              "interest_rate_can              float64\n",
              "index_W.BCPI                   float64\n",
              "index_W.BCNE                   float64\n",
              "index_W.ENER                   float64\n",
              "index_W.MTLS                   float64\n",
              "index_W.FOPR                   float64\n",
              "index_W.AGRI                   float64\n",
              "index_W.FISH                   float64\n",
              "index_WGTS.AGRI                float64\n",
              "index_WGTS.BRENT               float64\n",
              "index_WGTS.COAL                float64\n",
              "index_WGTS.FISH                float64\n",
              "index_WGTS.FOPR                float64\n",
              "index_WGTS.MTLS                float64\n",
              "index_WGTS.NATURALGAS          float64\n",
              "index_WGTS.WCC                 float64\n",
              "index_WGTS.WTI                 float64\n",
              "us_bank_rate                   float64\n",
              "sent_bert_us_fin               float64\n",
              "sent_bert_us_gen               float64\n",
              "sent_bert_can_fin_sentiment    float64\n",
              "sent_bert_can_gen_sentiment    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt1388vDkr37",
        "outputId": "165dc901-ddbc-4131-cdb4-e2b028c310bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1028250"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y_exp'] = np.full(df.shape[0], -1)\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    try:\n",
        "        two_weeks_from_current_date = datetime.datetime.strptime(row.date, \"%Y-%m-%d\") + datetime.timedelta(weeks=2)\n",
        "\n",
        "        futur_rate = list(df.loc[df['date'] == str(two_weeks_from_current_date.date())].rate)[0]\n",
        "        df.loc[i, 'y_exp' ] = futur_rate\n",
        "    except: \n",
        "        break\n",
        "\n",
        "df = df.loc[df.y_exp >= 0]"
      ],
      "metadata": {
        "id": "UmMOdEr7jOin"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AP-pGyNcefqF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcVJ1V48_yIY",
        "outputId": "4c5edf65-2599-4c92-d67f-4c56601a2b1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307924"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_sequences(seq_size, obs, y):\n",
        "    x = []\n",
        "    y_out = []\n",
        "\n",
        "    for i in range(len(obs)-seq_size):\n",
        "        #print(i)\n",
        "        window = obs[i:(i+seq_size)]\n",
        "        after_window = y[i+seq_size - 1]\n",
        "        window = [x for x in window]\n",
        "        x.append(window)\n",
        "        y_out.append(after_window)\n",
        "        \n",
        "    return np.array(x), np.array(y_out)"
      ],
      "metadata": {
        "id": "h4GM-h18vBdk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_test_val(df):\n",
        "    # Split train val test datasets\n",
        "    test_cutting_date = '2022-05-01'\n",
        "    val_cutting_date = '2022-02-01'\n",
        "    df_train = df[df['date'] < val_cutting_date]\n",
        "    df_val = df[(df['date'] >= val_cutting_date) &\n",
        "                (df['date'] < test_cutting_date)]\n",
        "    df_test = df[df['date'] >= test_cutting_date]\n",
        "    \n",
        "    return df_train, df_val, df_test"
      ],
      "metadata": {
        "id": "z-7UdlJ3z4Ov"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df, cols_to_keep, seq_size):\n",
        "    df_train, df_val, df_test = split_train_test_val(df)\n",
        "\n",
        "\n",
        "    x_train = df_train[cols_to_keep].to_numpy()\n",
        "    y_train = df_train['y_exp'].to_numpy()\n",
        "\n",
        "    x_val = df_val[cols_to_keep].to_numpy()\n",
        "    y_val = df_val['y_exp'].to_numpy()\n",
        "\n",
        "    x_test = df_test[cols_to_keep].to_numpy()\n",
        "    y_test = df_test['y_exp'].to_numpy()\n",
        "\n",
        "    x_train, y_train = to_sequences(seq_size, x_train, y_train)\n",
        "    x_val, y_val = to_sequences(seq_size, x_val, y_val)\n",
        "    x_test, y_test = to_sequences(seq_size, x_test, y_test)\n",
        "\n",
        "    print(\"Train: {}\".format(x_train.shape))\n",
        "    print(\"Val: {}\".format(x_val.shape))\n",
        "    print(\"Test: {}\".format(x_test.shape))\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "oT-aECF6j35I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "ONTm4Bv0g0Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "SfWPrBVagm1k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "    \n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "ocTQunDdPbXq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nxstIb5-jZNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(x_train, y_train, x_val, y_val):\n",
        "    input_shape = x_train.shape[1:]\n",
        "\n",
        "    model = build_model(\n",
        "        input_shape,\n",
        "        head_size=256,\n",
        "        num_heads=4,\n",
        "        ff_dim=4,\n",
        "        num_transformer_blocks=4,\n",
        "        mlp_units=[128],\n",
        "        mlp_dropout=0.4,\n",
        "        dropout=0.25,\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mean_squared_error\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    )\n",
        "\n",
        "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "    model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=200,\n",
        "        batch_size=64,\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cEkxZjVhkwzY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating"
      ],
      "metadata": {
        "id": "DzCKZO9Ag189"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(df, cols_to_keep, seq_size, nb_trials=5):\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = prepare_data(df, cols_to_keep, seq_size)\n",
        "\n",
        "    errors = []\n",
        "    models = []\n",
        "    smallest_error = None\n",
        "\n",
        "    for i in range(nb_trials):\n",
        "        model = train(x_train, y_train, x_val, y_val)\n",
        "        error = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "        if not smallest_error or smallest_error > error:\n",
        "            smallest_error = error\n",
        "\n",
        "        errors.append(error)\n",
        "        models.append(model)\n",
        "    \n",
        "    print('mean: ', np.mean(errors), 'var: ', np.var(errors))\n",
        "    print('smallest error: ', smallest_error)\n",
        "\n",
        "    return models"
      ],
      "metadata": {
        "id": "vCdDHbM1pYjJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-5 of the features based on LSTM results"
      ],
      "metadata": {
        "id": "1TiqYHVf6aDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_keep = [\n",
        "    'interest_rate_can',\n",
        "    'index_WGTS.BRENT',\n",
        "    'rate',\n",
        "    'ti_rate_rsi_14',\n",
        "    'sent_fin_can_litigious',\n",
        "]\n",
        "\n",
        "seq_size = 20\n",
        "models = run(df, cols_to_keep, seq_size, nb_trials=5)"
      ],
      "metadata": {
        "id": "i6YcGiuhEkKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(models):\n",
        "    model.save(f\"{DIR_PATH}/transformer_models/model_{i}\")"
      ],
      "metadata": {
        "id": "hdXfo9kLGwuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}