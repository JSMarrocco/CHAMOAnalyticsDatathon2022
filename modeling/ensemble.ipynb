{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "Before running, make sure you have downloaded th ezip file for each model, extracted the model from it, and saved it in a directory named \"model\". Models can be access on [google drive](https://drive.google.com/drive/folders/1ldH5LbvOHNMP_eBM74szzdETlycwVdjW?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 11:44:53.467992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "from tensorflow import keras\n",
    "import pathlib\n",
    "from  tensorflow.keras.metrics import mean_squared_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_and_clean_master_dataset()\n",
    "\n",
    "df_train, df_val, df_test = utils.split_train_test_val(df)\n",
    "\n",
    "X_train, y_train = utils.split_Xy(df_train)\n",
    "X_val, y_val = utils.split_Xy(df_val)\n",
    "X_test, y_test = utils.split_Xy(df_test)\n",
    "\n",
    "X_train, scaler = utils.normalize(X_train, train=True)\n",
    "X_val, _ = utils.normalize(X_val, train=False, scaler=scaler)\n",
    "X_test, _ = utils.normalize(X_test, train=False, scaler=scaler)\n",
    "\n",
    "i =7\n",
    "X_train, X_val, X_test = X_train[utils.cols[:i+1]], X_val[utils.cols[:i+1]], X_test[utils.cols[:i+1]]\n",
    "\n",
    "\n",
    "X_train, y_train = utils.to_batch(X_train, y_train)\n",
    "X_val, y_val = utils.to_batch(X_val, y_val)\n",
    "X_test, y_test = utils.to_batch(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 11:47:13.502968: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "crnt_dir = pathlib.Path('.').parent.resolve()\n",
    "lstm_models = []\n",
    "for i in range(5):\n",
    "    lstm_models.append(keras.models.load_model(crnt_dir/'lstm'/f'model_{i}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0032882523>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lstms = []\n",
    "for model in lstm_models:\n",
    "    y_pred_lstms.append(model(X_test))\n",
    "\n",
    "y_pred_lstm = lstm_models[0](X_test)\n",
    "mean_squared_error(y_test.to_numpy(), y_pred_lstm.numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_and_clean_master_dataset()\n",
    "\n",
    "df_train, df_val, df_test = utils.split_train_test_val(df)\n",
    "\n",
    "X_train, y_train = utils.split_Xy(df_train)\n",
    "X_val, y_val = utils.split_Xy(df_val)\n",
    "X_test, y_test = utils.split_Xy(df_test)\n",
    "\n",
    "i = 4\n",
    "X_train, X_val, X_test = X_train[utils.cols[:i+1]], X_val[utils.cols[:i+1]], X_test[utils.cols[:i+1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnt_dir = pathlib.Path('.').parent.resolve()\n",
    "nn_models = []\n",
    "for i in range(5):\n",
    "    nn_models.append(keras.models.load_model(crnt_dir/'DNN'/f'model_{i}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0007316234>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take into account sliding window of models\n",
    "X_test, y_test = X_test[20:], y_test[20:]\n",
    "\n",
    "y_pred_nns = []\n",
    "for model in nn_models:\n",
    "    y_pred_nns.append(np.array([p[0] for p in model.predict(X_test)]))\n",
    "\n",
    "y_pred_nn = np.array([p[0] for p in nn_models[0].predict(X_test)])\n",
    "mean_squared_error(y_test.to_numpy(), y_pred_nn.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.load_and_clean_master_dataset()\n",
    "\n",
    "df_train, df_val, df_test = utils.split_train_test_val(df)\n",
    "\n",
    "X_train, y_train = utils.split_Xy(df_train)\n",
    "X_val, y_val = utils.split_Xy(df_val)\n",
    "X_test, y_test = utils.split_Xy(df_test)\n",
    "\n",
    "i = 4\n",
    "X_train, X_val, X_test = X_train[utils.cols[:i+1]], X_val[utils.cols[:i+1]], X_test[utils.cols[:i+1]]\n",
    "\n",
    "X_train, y_train = utils.to_batch(X_train, y_train)\n",
    "X_val, y_val = utils.to_batch(X_val, y_val)\n",
    "X_test, y_test = utils.to_batch(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnt_dir = pathlib.Path('.').parent.resolve()\n",
    "transformer_models = []\n",
    "for i in range(2):\n",
    "    transformer_models.append(keras.models.load_model(crnt_dir/'transformer'/f'model_{i+1}'))\n",
    "transformer_model = keras.models.load_model(crnt_dir/'transformer'/'model_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0011829048>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_transformers = []\n",
    "for model in transformer_models[1:]:\n",
    "    y_pred_transformers.append(model(X_test))\n",
    "\n",
    "y_pred_transformer = transformer_model(X_test)\n",
    "mean_squared_error(y_test.to_numpy(), y_pred_transformer.numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nns = [y_pred_nn.reshape((-1,1)) for y_pred_nn in y_pred_nns ]\n",
    "y_pred = np.mean([*y_pred_nns, *y_pred_lstms, *y_pred_transformers], axis=0)\n",
    "ensemble_mse = mean_squared_error(y_test.to_numpy(), y_pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final (ensemble) MSE is 0.0005525783053599298\n"
     ]
    }
   ],
   "source": [
    "print(f'Final (ensemble) MSE is {ensemble_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Drawdown: -0.10428985953330994\n",
      "Mean Bias: 0.006440697781402273\n",
      "variance: 0.0010006490629166365\n"
     ]
    }
   ],
   "source": [
    "pmin = y_pred.min(axis=0)\n",
    "pmax = y_pred.max(axis=0)\n",
    "\n",
    "drawdown = (pmin-pmax) / pmax \n",
    "print(f\"Mean Drawdown: {np.mean(drawdown)}\")\n",
    "\n",
    "bias = np.abs(np.mean(y_pred - np.expand_dims(y_test, axis=-1)))\n",
    "print(f\"Mean Bias: {np.mean(bias)}\")\n",
    "\n",
    "variance = np.mean(np.var([*y_pred_nns, *y_pred_lstms, *y_pred_transformers], axis=0))\n",
    "print(f\"variance: {variance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10428986], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3126215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8885cedc3999557674b111d5f865ee3ff77904464a9ea6e0a42cb491ffcb7784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
